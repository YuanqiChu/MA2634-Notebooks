{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SKWLcTwBkh2k"
   },
   "source": [
    "# MA2634: Machine Learning for Artificial Intelligence (NCUT)\n",
    "\n",
    "> **Adapted from MA5634: Fundamentals of Machine Learning (Simon Shaw)**  \n",
    "> This MA2634 notebook updates framing, outcomes, and assessment alignment per the MA2634 module block (NCUT), while acknowledging Simon Shaw’s original MA5634 materials.\n",
    "\n",
    "---\n",
    "\n",
    "## Acknowledgements (MA5634 sources)\n",
    "\n",
    "# MA5634: Fundamentals of Machine Learning\n",
    "\n",
    "#### *variationalform* <https://variationalform.github.io/>\n",
    "\n",
    "#### *Just Enough: progress at pace*\n",
    "\n",
    "<https://variationalform.github.io/>\n",
    "\n",
    "<https://github.com/variationalform>\n",
    "\n",
    "Simon Shaw  \n",
    "<https://www.brunel.ac.uk/people/simon-shaw>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kudatG6Dkh2o"
   },
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td>\n",
    "<img src=\"https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1\" style=\"height:18px\"/>\n",
    "<img src=\"https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1\" style=\"height:18px\"/>\n",
    "<img src=\"https://mirrors.creativecommons.org/presskit/icons/sa.svg?ref=chooser-v1\" style=\"height:18px\"/>\n",
    "</td>\n",
    "<td>\n",
    "\n",
    "<p>\n",
    "This work is licensed under CC BY-SA 4.0 (Attribution-ShareAlike 4.0 International)\n",
    "\n",
    "<p>\n",
    "Visit <a href=\"http://creativecommons.org/licenses/by-sa/4.0/\">http://creativecommons.org/licenses/by-sa/4.0/</a> to see the terms.\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Py8mT9DOkh2o"
   },
   "source": [
    "<table>\n",
    "<tr>\n",
    "<td>This document uses python</td>\n",
    "<td>\n",
    "<img src=\"https://www.python.org/static/community_logos/python-logo-master-v3-TM.png\" style=\"height:30px\"/>\n",
    "</td>\n",
    "<td>and also makes use of LaTeX </td>\n",
    "<td>\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/92/LaTeX_logo.svg/320px-LaTeX_logo.svg.png\" style=\"height:30px\"/>\n",
    "</td>\n",
    "<td>in Markdown</td>\n",
    "<td>\n",
    "<img src=\"https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png\" style=\"height:30px\"/>\n",
    "</td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5hf2coVkh2p"
   },
   "source": [
    "## What this is about\n",
    "\n",
    "You will be introduced to the **foundational principles of machine learning** with both their mathematical underpinning and their software incarnations. The course explores the role of machine learning (ML) in artificial intelligence (AI), along with the **ethical issues** surrounding the use of data and AI systems.\n",
    "\n",
    "You will learn to distinguish between:\n",
    "- **Regression and classification** problems  \n",
    "- **Supervised and unsupervised** learning approaches  \n",
    "- **Training, validation, and test** data sets, and their role in model evaluation  \n",
    "\n",
    "You will also encounter essential ideas such as:\n",
    "- **Cost and loss functions**, and the notion of optimisation  \n",
    "- **Decision boundaries** in classification  \n",
    "- **Bootstrap techniques** for assessing model variability  \n",
    "- **Clustering and neighbours methods** for unsupervised learning  \n",
    "- **Trees and perceptrons** as basic prediction machines  \n",
    "\n",
    "### Mathematics: “just enough, at pace”\n",
    "You are **not expected to be a mathematician**, but you will be expected to recall or learn the necessary basics in:\n",
    "- Vectors and matrices  \n",
    "- Random variables and simulation  \n",
    "- Differential calculus (only where required for cost/loss functions)  \n",
    "\n",
    "### Programming: “just enough, at pace”\n",
    "You are **not expected to be a computer scientist**, but **Python will be introduced and used as a tool**. Only the essential Python syntax, libraries, and techniques will be covered.  \n",
    "The emphasis will be on **doing and experimenting with ML models**, rather than proving theorems.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftF5vGdmkh2p"
   },
   "source": [
    "## Assessment\n",
    "\n",
    "- **25% Assignment**  \n",
    "  A small project requiring you to **choose, configure, and implement a machine learning classifier or clustering method**.  \n",
    "  Deliverables will include a short technical report (with code appendix) and clear communication of your results. Guidance and a detailed brief will be provided in class.\n",
    "\n",
    "- **75% Examination (2 hours)**  \n",
    "  A written exam focusing on theory, core concepts (e.g. regression vs. classification, supervised vs. unsupervised learning, validation methods, bootstrap, decision boundaries), and applied interpretation of results.  \n",
    "  **Revision and reflection time will be allocated** in the final weeks of the course.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z2fbL8gbkh2q"
   },
   "source": [
    "## Key Concepts: Glossary of Relevant Terms\n",
    "\n",
    "The first few of these are debatable, evolving, and subject to change and interpretation.  \n",
    "It is worth searching and reading for yourself — these are fast-growing areas.\n",
    "\n",
    "---\n",
    "\n",
    "#### Data Science\n",
    "An **interdisciplinary field** combining mathematics, computer science, and statistics with domain expertise.  \n",
    "It involves extracting knowledge and insight from structured and unstructured data, often at scale.\n",
    "\n",
    "#### Data Analytics\n",
    "The **systematic computational analysis of data** to discover patterns, trends, and value.  \n",
    "Often used to support decision-making and business intelligence.\n",
    "\n",
    "#### Data Engineering\n",
    "The stewardship, cleaning, storage, and preparation of data, including pipelines and warehousing, to make data reliable and usable for analysis and machine learning.\n",
    "\n",
    "#### Machine Learning (ML)\n",
    "A branch of AI focused on building algorithms that **learn patterns from data** to make predictions or decisions without being explicitly programmed.  \n",
    "Includes both **supervised** (with labelled outcomes) and **unsupervised** (finding structure without labels) approaches.\n",
    "\n",
    "#### Supervised Learning\n",
    "Learning from labelled data: input–output pairs are provided, and the task is to generalise to unseen cases.  \n",
    "Examples: regression (predicting continuous values), classification (predicting categories).\n",
    "\n",
    "#### Unsupervised Learning\n",
    "Learning from unlabelled data: the task is to uncover structure such as clusters, latent factors, or relationships.  \n",
    "Examples: clustering, dimensionality reduction (e.g. PCA).\n",
    "\n",
    "#### Cost and Loss Functions\n",
    "Mathematical formulations that measure the “error” of a model.  \n",
    "- **Loss function**: error on a single example.  \n",
    "- **Cost function**: aggregated error over the dataset.  \n",
    "Optimisation methods aim to minimise these.\n",
    "\n",
    "#### Validation / Test Sets\n",
    "- **Validation set**: used for model selection and tuning hyperparameters.  \n",
    "- **Test set**: held back until the very end to give an unbiased estimate of model performance.\n",
    "\n",
    "#### Bootstrap\n",
    "A **resampling technique** that provides estimates of uncertainty (e.g. confidence intervals) by repeatedly sampling (with replacement) from the observed data.\n",
    "\n",
    "#### Decision Boundary\n",
    "A surface in the feature space that separates different classes assigned by a model.  \n",
    "Understanding decision boundaries helps interpret classification models.\n",
    "\n",
    "#### Perceptron\n",
    "A simple linear model inspired by biological neurons, able to separate data that are linearly separable. Forms the basis for more complex neural networks.\n",
    "\n",
    "#### Ethics in AI/ML\n",
    "Critical consideration of **bias, fairness, accountability, and transparency** in data and models.  \n",
    "Covers issues of data provenance, privacy, and responsible deployment of AI systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBTNURZUkh2q"
   },
   "source": [
    "#### Artificial Intelligence\n",
    "\n",
    "The development and deployment of digital systems that can effectively substitute for humans in\n",
    "tasks beyond the routine application of fixed rules. When you talk to your home assistant, your\n",
    "phone, or your satellite TV receiver, or your car, or your laptop, and so on, it has no idea\n",
    "what you are going to say. It doesn't have a bank of pre-answered questions, but instead it\n",
    "responds dynamically to what it hears. It has been trained on data, and it has learned how to\n",
    "respond. Incidentally, how do you think these systems even understand what you said? As a child,\n",
    "it took you months to begin to understand human speech..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPYmlauQkh2q"
   },
   "source": [
    "#### Machine Learning\n",
    "\n",
    "The development and deployment of algorithms that are able to learn from data without explicit instructions,\n",
    "and then analyze, predict, or otherwise draw inferences, from unseen data. These algorithms would typically\n",
    "be expected to add measurable value by their performance.\n",
    "\n",
    "> *Consider for example an algorithm that predicted __tails__ for every coin flip. It's\n",
    "> right half the time* - but there's no value in that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdsON1gCkh2q"
   },
   "source": [
    "#### Learning\n",
    "\n",
    "Machine learning models do not have intrinsic knowledge but instead learn from data.\n",
    "Typically a data set comprises a list of items each of which has one or more\n",
    "*features* which correspond to a *label*. We'll see some examples of this below.\n",
    "\n",
    "We think of the features as being inputs to the machine learning model, and the label\n",
    "as being the output. Typically we want to be able to feed in new features, and have\n",
    "the model predict the label.\n",
    "\n",
    "To do this we need a **training data set** so that the model can learn how to map the\n",
    "features to the label: the *input to the output*.\n",
    "\n",
    "There are three basic learning paradigms:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elqmdvNEkh2r"
   },
   "source": [
    "- **Supervised Learning**:\n",
    "Here the data is labelled. This means that for a given set of features, or inputs, we also know\n",
    "their labels, or outputs. Examples of this are where...\n",
    "  - We could have a list of features of insured drivers, such as age, time since they passed\n",
    "  their driving test, type of car, locality, and along with those features a monetary\n",
    "  value on their accident claim. The task would be to learn how much of an insurance premium\n",
    "  to charge to a new customer once those features have been determined.\n",
    "  - We might have a bank of images of handwritten digits, and for each image we know what\n",
    "  digit is represented. The MNIST database of handwritten digits, see\n",
    "  <http://yann.lecun.com/exdb/mnist/> or <https://en.wikipedia.org/wiki/MNIST_database>\n",
    "  for example, is a well known example of this. The task is to learn how to predict\n",
    "  what digit is captured by a new image. This could be used in ANPR systems for example,\n",
    "  <https://en.wikipedia.org/wiki/Automatic_number-plate_recognition>.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNRwkBCEkh2r"
   },
   "source": [
    "- **Unsupervised Learning**:\n",
    "This is where we only know the features and we want to cluster the data in such a way\n",
    "that a set of similar features can be assiociated with some common characteristic (the label).\n",
    "  - This can be used on data where the anlayst doesn't initially know what they are looking\n",
    "  for. For example, a retailer might have a mass of data of customer age, locale, average spend,\n",
    "  types of purchased item, time of day of purchase, day of week of purchase, time of year etc.\n",
    "  What characteristics can be used to group these customers? How can advertising be targetted?\n",
    "  - principal component analysis seeks to re-orient data so that its dominant statistical\n",
    "  properties are revealed. We'll see this later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJGX5kYWkh2r"
   },
   "source": [
    "- **Reinforcement Learning**:\n",
    "This seeks to strike a balance between the two above. There are no labels, but instead, as time\n",
    "progresses the learning algorithm has a *reward* variable which is increased when an action it\n",
    "has learned has resulted in a measurable benefit. Over time the algorithm develops a policy to\n",
    "inform its actions.\n",
    "\n",
    "This last is a major topic and will not be covered in these lectures. We will see examples of\n",
    "the first two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXuc22Oikh2r"
   },
   "source": [
    "#### Regression and Classification\n",
    "\n",
    "Our algorithms will be developed to perform one of the following tasks:\n",
    "\n",
    "- **Regression:** here the output, the label, can take any value in a continuous set. For example,\n",
    "  the height of a tree, given local climate, soil type, genus, age since planting, could be\n",
    "  considered to be any non-negative real number (although not with equal probability).\n",
    "\n",
    "- **Classification:** in this case the label will be deemed to be one of a certain class. For\n",
    "  example, in the handwritten digits example above, the output will be one of the digits\n",
    "  $\\{0,1,2,3,\\ldots,9\\}$.\n",
    "\n",
    "Some of the algorithms we study will be able to perform both the regression and clustering tasks,\n",
    "although we wont always delve deeply into both capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PU9HGub9kh2r"
   },
   "source": [
    "## Reading List\n",
    "\n",
    "For the data science, our main sources of information are as follows:\n",
    "    \n",
    "- MML: Mathematics for Machine Learning, by Marc Peter Deisenroth, A. Aldo Faisal, and Cheng Soon Ong.\n",
    "  Cambridge University Press. <https://mml-book.github.io>.\n",
    "- MLFCES: Machine Learning: A First Course for Engineers and Scientists, by Andreas Lindholm,\n",
    "  Niklas Wahlström, Fredrik Lindsten, Thomas B. Schön. Cambridge University Press.\n",
    "  <http://smlbook.org>.\n",
    "- FCLA: A First Course in Linear Algebra, by Ken Kuttler,\n",
    "  <https://math.libretexts.org/Bookshelves/Linear_Algebra/A_First_Course_in_Linear_Algebra_(Kuttler)>\n",
    "- AP: Applied Probability, by Paul Pfeiffer\n",
    "  <https://stats.libretexts.org/Bookshelves/Probability_Theory/Applied_Probability_(Pfeiffer)>\n",
    "- IPDS: Introduction to Probability for Data Science, by Stanley H. Chan,\n",
    "  <https://probability4datascience.com>\n",
    "- SVMS: Support Vector Machines Succinctly, by Alexandre Kowalczyk,\n",
    "  <https://www.syncfusion.com/succinctly-free-ebooks/support-vector-machines-succinctly>\n",
    "- VMLS: Introduction to Applied Linear Algebra - Vectors, Matrices, and Least Squares,\n",
    "  by Stephen Boyd and Lieven Vandenberghe,\n",
    "  <https://web.stanford.edu/~boyd/vmls/>\n",
    "\n",
    "\n",
    "All of the above can be accessed legally and without cost.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VjsdjEUYkh2s"
   },
   "source": [
    "There are also these useful references for coding:\n",
    "\n",
    "- PT: `python`: <https://docs.python.org/3/tutorial>\n",
    "- NP: `numpy`: <https://numpy.org/doc/stable/user/quickstart.html>\n",
    "- MPL: `matplotlib`: <https://matplotlib.org>\n",
    "\n",
    "The capitalized abbreviations will be used throughout to refer to these sources. For example, we could\n",
    "say *See [MLFCES, Chap 2, Sec. 1] for more discussion of __Supervised Learning__*. This would\n",
    "just be a quick way of saying\n",
    "\n",
    "> Look in Section 1, of Chapter 2, of Machine Learning: A First Course for Engineers and\n",
    "> Scientists, by Andreas Lindholm, Niklas Wahlström, Fredrik Lindsten, Thomas B. Schön,\n",
    "> for more discussion of supervised learning.\n",
    "\n",
    "There will be other sources shared as we go along. For now these will get us a long way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p0VG4ckAkh2s"
   },
   "source": [
    "## Coding: `python` and some data sets\n",
    "\n",
    "For each of our main topics we will see some example data, discuss a means of working with it,\n",
    "and then implement those means in code. We will develop enough theory so as to understand how\n",
    "the codes work, but our main focus will be the intution behind the method, and the effective\n",
    "problem solving using code.\n",
    "\n",
    "We choose `python` because its use in both the commercial and academic data science\n",
    "arena seems to be pre-eminent.\n",
    "\n",
    "The data science techniques and algorithms we will study, and the supporting technology\n",
    "like graphics and number crunching, are implemented in well-known and well-documented\n",
    "`python` libraries. These are the main ones we will use:\n",
    "\n",
    "- `matplotlib`: used to create visualizations, plotting 2D graphs in particular.\n",
    "- `numpy`: this is *numerical python*, it is used for array processing which for us\n",
    "   will usually mean the numerical calculations involving vectors and matrices.\n",
    "- `scikit-learn`: a set of well documented and easy to use tools for predictive data analysis.\n",
    "- `pandas`: a data analysis tool, used for the storing and manipulation of data.\n",
    "- `seaborn`: a data visualization library for attractive and informative statistical graphics.\n",
    "\n",
    "There will be others, but these are the main ones. Let's look at some examples of how to use these\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wLJlVk7kh2s"
   },
   "source": [
    "## Binder, Anaconda, Jupyter - a first look at some data\n",
    "\n",
    "Eventually we will use the anaconda distribution to access `python` and the libraries\n",
    "we need. The coding itself will be carried out in a Jupyter notebook. We'll go through this\n",
    "in an early lab session. We'll start though with Binder: click here:\n",
    "\n",
    "<https://mybinder.org/v2/gh/variationalform/FML.git/HEAD>\n",
    "\n",
    "Let's see some code and some data. In the following cell we import `seaborn` and look at\n",
    "the names of the built in data sets. The `seaborn` library, <https://seaborn.pydata.org>,\n",
    "is designed for data visualization. It uses `matplotlib`, <https://matplotlib.org>,\n",
    "which is a graphics library for `python`.\n",
    "\n",
    "If you want to dig deeper, you can look at\n",
    "<https://blog.enterprisedna.co/how-to-load-sample-datasets-in-python/>\n",
    "and <https://github.com/mwaskom/seaborn-data> for the background - but you don't need to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4230,
     "status": "ok",
     "timestamp": 1757774485120,
     "user": {
      "displayName": "Yuanqi Chu",
      "userId": "01055780213744705859"
     },
     "user_tz": -480
    },
    "id": "0-b6v0TQkh2s",
    "outputId": "5272f26f-e5d6-482f-ce7a-3f764215055e"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# we can now refer to the seaborn library functions using 'sns'\n",
    "# note that you can use another character string - but 'sns' is standard.\n",
    "\n",
    "# note that # is used to write 'comments'\n",
    "# Now let's get the names of the built-in data sets.\n",
    "sns.get_dataset_names()\n",
    "\n",
    "# type SHIFT=RETURN to execute the highlighted (active) cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlDPsw05kh2t"
   },
   "source": [
    "### The `taxis` data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "executionInfo": {
     "elapsed": 908,
     "status": "ok",
     "timestamp": 1757774491171,
     "user": {
      "displayName": "Yuanqi Chu",
      "userId": "01055780213744705859"
     },
     "user_tz": -480
    },
    "id": "vW5D1FwDkh2u",
    "outputId": "c4d19fbc-c9b6-4d31-ac3a-d9ad9a856fd0"
   },
   "outputs": [],
   "source": [
    "# let's take a look at 'taxis'\n",
    "dft = sns.load_dataset('taxis')\n",
    "# this just plots the first few lines of the data\n",
    "dft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "executionInfo": {
     "elapsed": 585,
     "status": "ok",
     "timestamp": 1757774504679,
     "user": {
      "displayName": "Yuanqi Chu",
      "userId": "01055780213744705859"
     },
     "user_tz": -480
    },
    "id": "gmpP-v3vkh2u",
    "outputId": "9c4751db-820f-4e81-f300-e0a5528a4c68"
   },
   "outputs": [],
   "source": [
    "# this will plot the last few lines... There are 6433 records (Why?)\n",
    "dft.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3PK7R_Wkh2u"
   },
   "source": [
    "What we are seeing here is a **data frame**. It is furnished by the `pandas`\n",
    "library: <https://pandas.pydata.org> which is used by the `seaborn` library\n",
    "to store its example data sets.\n",
    "\n",
    "Each row of the data frame corresponds to a single **data point**, which we\n",
    "could also call an `observation` or `measurement` (depending on context).\n",
    "\n",
    "Each column (except the left-most) corresponds to a **feature** of the data\n",
    "point. The first column is just an index giving the row number. Note that this\n",
    "index starts at zero - so, for example, the third row will be labelled/indexed\n",
    "as $2$. Be careful of this - it can be confusing.\n",
    "\n",
    "In this, the variable dft is a pandas data frame: dft = 'data frame taxis'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 446,
     "status": "ok",
     "timestamp": 1757774523070,
     "user": {
      "displayName": "Yuanqi Chu",
      "userId": "01055780213744705859"
     },
     "user_tz": -480
    },
    "id": "S9yp3CLOkh2u",
    "outputId": "3e55d959-58ae-4822-8900-b3970242cdac"
   },
   "outputs": [],
   "source": [
    "# let's print the data frame...\n",
    "print(dft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oFKf8swRkh2u"
   },
   "source": [
    "#### Visualization\n",
    "\n",
    "Rows and rows of numbers aren't that helpful.\n",
    "\n",
    "seaborn makes visualization easy - here is a scatter plot of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "executionInfo": {
     "elapsed": 595,
     "status": "ok",
     "timestamp": 1757774532191,
     "user": {
      "displayName": "Yuanqi Chu",
      "userId": "01055780213744705859"
     },
     "user_tz": -480
    },
    "id": "ayhFUB1Vkh2u",
    "outputId": "be7ea716-c387-4695-fc8a-0e1aa68b1a63"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=dft, x=\"distance\", y=\"fare\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKTJwnGpkh2u"
   },
   "source": [
    "> **THINK ABOUT**: it looks like fare is roughly proportional to distance.\n",
    "> But what could cause the outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "executionInfo": {
     "elapsed": 1700,
     "status": "ok",
     "timestamp": 1757774745424,
     "user": {
      "displayName": "Yuanqi Chu",
      "userId": "01055780213744705859"
     },
     "user_tz": -480
    },
    "id": "pnI8AmLakh2u",
    "outputId": "8ec19b91-051b-41fb-9d8a-b3dca70f4497"
   },
   "outputs": [],
   "source": [
    "# here's another example\n",
    "sns.scatterplot(data=dft, x=\"pickup_borough\", y=\"tip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "executionInfo": {
     "elapsed": 1216,
     "status": "ok",
     "timestamp": 1757774752901,
     "user": {
      "displayName": "Yuanqi Chu",
      "userId": "01055780213744705859"
     },
     "user_tz": -480
    },
    "id": "ubEU8VLBkh2v",
    "outputId": "8e609342-f58f-4897-c9d3-4405bba34d0f"
   },
   "outputs": [],
   "source": [
    "# is the tip proportional to the fare?\n",
    "sns.scatterplot(data=dft, x=\"fare\", y=\"tip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LxiwoyG5kh2v"
   },
   "outputs": [],
   "source": [
    "# is the tip proportional to the distance?\n",
    "sns.scatterplot(data=dft, x=\"distance\", y=\"tip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O5Jzxs5ckh2v"
   },
   "source": [
    "### The `tips` data set\n",
    "\n",
    "Let's look now at the `tips` data set. Along the way we'll see a few more\n",
    "ways we can use the data frame object\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mHy9ZFDZkh2v"
   },
   "outputs": [],
   "source": [
    "# load the data - dft: data frame tips\n",
    "# note that this overwrites the previous 'value/meaning' of dft\n",
    "dft = sns.load_dataset('tips')\n",
    "dft.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPdtl4Hakh2v"
   },
   "source": [
    "An extensive list of data frame methods/functions can be found here:\n",
    "<https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame>\n",
    "Let's look at some of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1vM1T0G8kh2w"
   },
   "outputs": [],
   "source": [
    "print(dft.info)\n",
    "print('The shape of the data frame is: ', dft.shape)\n",
    "print('The size of the data frame is: ', dft.size)\n",
    "print('Note that 244*7 =', 244*7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ohW_0E5mkh2w"
   },
   "source": [
    "#### Visualization\n",
    "\n",
    "Again, numbers aren't always that helpful. Plots often give us more insight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J8o9qA2Okh2w"
   },
   "outputs": [],
   "source": [
    "dft.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bT9qfnLTkh2w"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=dft, x=\"total_bill\", y=\"tip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VVB00JtNkh2w"
   },
   "source": [
    "#### Statistics and Probability\n",
    "\n",
    "You're assumed to be familiar with basic terms and concepts in these areas,\n",
    "but we will revise and review those that we need later.\n",
    "\n",
    "We can get some basic stats for our data set with the `describe()` method..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j6MZDM_6kh2x"
   },
   "outputs": [],
   "source": [
    "# here are some descriptive statistics\n",
    "dft.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgIxyywxkh2x"
   },
   "source": [
    "### The `anscombe` data set\n",
    "\n",
    "This is pretty famous. There are four sets of 11 coordinate pairs.\n",
    "When plotted they look completely different.\n",
    "But they have the same summary statistics (at least the common ones).\n",
    "\n",
    "See <https://en.wikipedia.org/wiki/Anscombe%27s_quartet>\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/7/7e/Julia-anscombe-plot-1.png\" style=\"height:300px\"/>\n",
    "\n",
    "Image Credit: `https://upload.wikimedia.org/wikipedia/commons/7/7e/Julia-anscombe-plot-1.png`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tMteD6Z4kh2x"
   },
   "source": [
    "Let's load the data set and take a look at it - we can look at the head and tail of the\n",
    "table just as we did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FeuFU8zFkh2x"
   },
   "outputs": [],
   "source": [
    "dfa = sns.load_dataset('anscombe')\n",
    "# look at how we get an apostrophe in the string...\n",
    "print(\"The size of Anscombe's data set is:\", dfa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tnmugEVBkh2x"
   },
   "outputs": [],
   "source": [
    "dfa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QhWfhA0akh2x"
   },
   "outputs": [],
   "source": [
    "dfa.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYjUCfuqkh2x"
   },
   "source": [
    "It looks like the four data sets are in the `dataset` column. How can we extract them as separate items?\n",
    "\n",
    "Well, one way is to print the whole dataset and see which rows correspond to each dataset. Like this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IT84VhrQkh2x"
   },
   "outputs": [],
   "source": [
    "print(dfa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "neNZN3qQkh2y"
   },
   "source": [
    "From this and the `head` and `tail` output above we can infer that there are four\n",
    "data sets: I, II, III and IV. They each contain $11$ pairs $(x,y)$.\n",
    "\n",
    "- The first set occupies rows $0,1,2,\\ldots,10$\n",
    "- The second set occupies rows $11,12,\\ldots,21$\n",
    "- The third set occupies rows $22,23,\\ldots,32$\n",
    "- The fourth set occupies rows $33,34,\\ldots,43$\n",
    "\n",
    "However, this kind of technique is not going to be useful if we have a data set\n",
    "with millions of data points (rows). We certainly wont want to print them all\n",
    "like we did above.\n",
    "\n",
    "Is there another way to determine the number of distinct feature values in a\n",
    "given column of the data frame?\n",
    "\n",
    "Fortunately, yes. We want to know how many different values the `dataset` column\n",
    "has. We can do it like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vxYeHSc2kh2y"
   },
   "outputs": [],
   "source": [
    "dfa.dataset.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ic3OnU7Vkh2y"
   },
   "source": [
    "We can count the number of different ones automatically too, by asking\n",
    "for the `shape` of the returned value. Here we go:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FYrd-DOkkh2y"
   },
   "outputs": [],
   "source": [
    "dfa.dataset.unique().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7eQ-fUNkh2y"
   },
   "source": [
    "This tell us that there are 4 items - as expected.\n",
    "Don't worry too much about it saying `(4,)` rather that just `4`.\n",
    "We'll come to that later when we discuss `numpy`\n",
    "(Numerical python: <https://numpy.org>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ScAG2Yxkh2y"
   },
   "source": [
    "Now, we want to extract each of the four datasets as separate data sets so we can work\n",
    "with them. We can do that by using `loc` to get the row-wise locations where each\n",
    "value of the `dataset` feature is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bMwJlrrQkh2y"
   },
   "source": [
    "For example, using the hints here\n",
    "<https://stackoverflow.com/questions/17071871/how-do-i-select-rows-from-a-dataframe-based-on-column-values>,\n",
    "to get the data for the sub-data-set `I` we can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JCUxOmV8kh2y"
   },
   "outputs": [],
   "source": [
    "dfa.loc[dfa['dataset'] == 'I']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZKaZoXWkh2y"
   },
   "source": [
    "Now we have this subset of data we can examine it - with a scatter plot\n",
    "for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J1hnsjD-kh2y"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=dfa.loc[dfa['dataset'] == 'I'], x=\"x\", y=\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UEKX5edkh2y"
   },
   "source": [
    "To really work properly with each subset we should extract them and give each\n",
    "of them a name that is meaningful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zzEmdxWDkh2y"
   },
   "outputs": [],
   "source": [
    "dfa1 = dfa.loc[dfa['dataset'] == 'I']\n",
    "dfa2 = dfa.loc[dfa['dataset'] == 'II']\n",
    "dfa3 = dfa.loc[dfa['dataset'] == 'III']\n",
    "dfa4 = dfa.loc[dfa['dataset'] == 'IV']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gqt42Ubkh2y"
   },
   "source": [
    "Now let's look at each of the four data sets in a scatter plot,\n",
    "and use the `describe` method to examine the summary statistics.\n",
    "\n",
    "The outcome is quite surprising..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_8BpwrFkh2z"
   },
   "source": [
    "#### dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o58BkkEtkh2z"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=dfa1, x=\"x\", y=\"y\")\n",
    "dfa1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_7VZTQcjkh2z"
   },
   "source": [
    "#### dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kDlwUHOdkh2z"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=dfa2, x=\"x\", y=\"y\")\n",
    "dfa2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEya_Fb9kh2z"
   },
   "source": [
    "#### dataset 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YwuYRvQGkh2z"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=dfa3, x=\"x\", y=\"y\")\n",
    "dfa3.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNJ9a4IYkh2z"
   },
   "source": [
    "#### dataset 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74qezOwdkh2z"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(data=dfa4, x=\"x\", y=\"y\")\n",
    "dfa4.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Em2r7Xukh2z"
   },
   "source": [
    "## Exercises\n",
    "\n",
    "For the `taxis` data set:\n",
    "\n",
    "1. Produce a scatterplot of \"dropoff_borough\" vs. \"tip\"\n",
    "2. Plot the dependence of fare on distance.\n",
    "\n",
    "```\n",
    "1: sns.scatterplot(data=ds, x=\"dropoff_borough\", y=\"tip\")\n",
    "2: sns.scatterplot(data=ds, x=\"distance\", y=\"tip\")\n",
    "```\n",
    "\n",
    "For the `tips` data set:\n",
    "\n",
    "1. What is the standard deviation of the tips?\n",
    "2. Plot the scatter of tip against the total bill\n",
    "3. Plot the scatter of total bill against day\n",
    "4. Plot the scatter of tip against gender\n",
    "\n",
    "```\n",
    "1: ds.describe()\n",
    "2: sns.scatterplot(data=ds, x=\"total_bill\", y=\"tip\")\n",
    "3: sns.scatterplot(data=ds, x=\"day\", y=\"total_bill\")\n",
    "4: sns.scatterplot(data=ds, x=\"sex\", y=\"tip\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Du1dO-M9kh2z"
   },
   "source": [
    "Ignore this - it is done in 2_vectors\n",
    "\n",
    "For the Anscombe data set:\n",
    "\n",
    "1. Which of the summary statistics for $x$ are the same or similar for each subset?\n",
    "1. Which of the summary statistics for $y$ are the same or similar for each subset?\n",
    "\n",
    "\n",
    "Look at the `diamonds` data set\n",
    "\n",
    "1. How many diamonds are listed there? How many attributes does each have?\n",
    "2. Scatter plot price against carat.\n",
    "\n",
    "```\n",
    "1: ds = sns.load_dataset('diamonds'); ds.shape: 53940 and 10\n",
    "2: sns.scatterplot(data=ds, x=\"carat\", y=\"price\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ng467tSEkh2z"
   },
   "source": [
    "Some of this originated from\n",
    "\n",
    "<https://stackoverflow.com/questions/38540326/save-html-of-a-jupyter-notebook-from-within-the-notebook>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4903,
     "status": "ok",
     "timestamp": 1757778913935,
     "user": {
      "displayName": "Yuanqi Chu",
      "userId": "01055780213744705859"
     },
     "user_tz": -480
    },
    "id": "4q21kYxZyNtb",
    "outputId": "66cb7674-06cc-442b-95fd-5493c2818f07"
   },
   "outputs": [],
   "source": [
    "!jupyter nbconvert --ClearOutputPreprocessor.enabled=True --inplace 1_intro.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gHcBMai8zkYF"
   },
   "outputs": [],
   "source": [
    "# Create a cleaned copy of the current notebook for GitHub viewing.\n",
    "# - Removes noisy setup cells (apt-get / pip / nbconvert / pandoc)\n",
    "# - Optionally removes specific headings\n",
    "# - Clears ALL outputs\n",
    "# - Saves as *_public.ipynb\n",
    "\n",
    "import json, re, pathlib\n",
    "from google.colab import _message\n",
    "\n",
    "raw = _message.blocking_request('get_ipynb')['ipynb']\n",
    "\n",
    "def is_noisy_code(cell_src: str) -> bool:\n",
    "    pat = r'(^|\\n)\\s*(!apt-get|!pip|%%bash|nbconvert|PDFExporter|xelatex|pandoc)\\b'\n",
    "    return re.search(pat, cell_src, re.I) is not None\n",
    "\n",
    "def is_remove_md(cell_src: str) -> bool:\n",
    "    # optional: hide internal notes sections by title keywords\n",
    "    return re.search(r'(Technical Notes|Production Workflow)', cell_src, re.I) is not None\n",
    "\n",
    "clean_cells = []\n",
    "for c in raw.get(\"cells\", []):\n",
    "    src = \"\".join(c.get(\"source\", []))\n",
    "    ctype = c.get(\"cell_type\")\n",
    "\n",
    "    drop = False\n",
    "    if ctype == \"code\" and is_noisy_code(src):\n",
    "        drop = True\n",
    "    if ctype == \"markdown\" and is_remove_md(src):\n",
    "        drop = True\n",
    "\n",
    "    if not drop:\n",
    "        # clear outputs & execution_count\n",
    "        if ctype == \"code\":\n",
    "            c[\"outputs\"] = []\n",
    "            c[\"execution_count\"] = None\n",
    "        clean_cells.append(c)\n",
    "\n",
    "raw[\"cells\"] = clean_cells\n",
    "\n",
    "# also scrub execution metadata for tidiness\n",
    "raw[\"metadata\"].pop(\"widgets\", None)\n",
    "\n",
    "out = pathlib.Path(\"1_intro.ipynb\")  # <-- rename if you want\n",
    "out.write_text(json.dumps(raw), encoding=\"utf-8\")\n",
    "print(f\"Wrote cleaned file: {out.resolve()}\")\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
